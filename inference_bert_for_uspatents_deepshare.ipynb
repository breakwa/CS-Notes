{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/breakwa/CS-Notes/blob/master/inference_bert_for_uspatents_deepshare.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TX7VIvln-IlV",
        "outputId": "b0bb07a3-b062-40c5-8422-fda95d706053"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/drive/MyDrive/kaggle/' #注意kaggle文件夹包含json文件\n",
        " \n",
        "os.chdir('/content/drive/MyDrive/kaggle/') #切换到kaggle文件夹\n",
        " \n",
        "# !kaggle competitions download -c h-and-m-personalized-fashion-recommendations#下载数据集即可\n",
        "# !unzip h-and-m-personalized-fashion-recommendations.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iGZDilkNpQ7",
        "outputId": "49f033f6-5a55-436e-f5e3-5c209d799629"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading us-patent-phrase-to-phrase-matching.zip to /content/drive/MyDrive/kaggle\n",
            "\r  0% 0.00/682k [00:00<?, ?B/s]\n",
            "\r100% 682k/682k [00:00<00:00, 34.0MB/s]\n",
            "Archive:  us-patent-phrase-to-phrase-matching.zip\n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions download -c us-patent-phrase-to-phrase-matching\n",
        "!unzip us-patent-phrase-to-phrase-matching.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-G7bqJFnM9Tx",
        "outputId": "989613ee-b29c-4cf0-bd77-85e7da76078a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading cpc-codes.zip to /content/drive/MyDrive/kaggle\n",
            "  0% 0.00/5.41M [00:00<?, ?B/s]\n",
            "100% 5.41M/5.41M [00:00<00:00, 80.4MB/s]\n",
            "Downloading deberta-v3-large.zip to /content/drive/MyDrive/kaggle\n",
            " 98% 755M/770M [00:04<00:00, 195MB/s]\n",
            "100% 770M/770M [00:04<00:00, 169MB/s]\n",
            "Downloading us-patent-deberta-simple.zip to /content/drive/MyDrive/kaggle\n",
            "100% 5.44G/5.44G [02:20<00:00, 76.0MB/s]\n",
            "100% 5.44G/5.44G [02:20<00:00, 41.5MB/s]\n",
            "usage: kaggle [-h] [-v] {competitions,c,datasets,d,kernels,k,config} ...\n",
            "kaggle: error: unrecognized arguments: --unzip\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d xhlulu/cpc-codes --unzip\n",
        "!kaggle datasets download -d jonathanchan/deberta-v3-large --unzip\n",
        "!kaggle datasets download -d leehann/us-patent-deberta-simple --unzip\n",
        "!kaggle kernels pull code/gauravbrills/folds-dump-the-two-paths-fix --unzip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8lMPKcIP_KZ",
        "outputId": "ec5ca47d-c0df-4c7e-b45b-c68e93bd2205"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 38.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 63.0 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.6.0-py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 3.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.6.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsKxK3R8QcZX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXBvhsA49OxB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "import shutil\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import transformers\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig, AutoModel\n",
        "\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jI4EFBA9OxE"
      },
      "source": [
        "# Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tyElLYf09OxF"
      },
      "outputs": [],
      "source": [
        "class CFG_DEB_SIMPLE:\n",
        "    input_path = '../input/us-patent-phrase-to-phrase-matching/'\n",
        "    model_path = '../input/deberta-v3-large/deberta-v3-large'\n",
        "    \n",
        "    learning_rate = 2e-5\n",
        "    weight_decay = 0.01\n",
        "    num_fold = 4\n",
        "    epochs = 5\n",
        "    batch_size = 64\n",
        "    max_input_length = 130\n",
        "    batch_size = 64\n",
        "    num_workers = 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJEmEiOl9OxG"
      },
      "source": [
        "# Preproc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHNfpoN59OxG"
      },
      "outputs": [],
      "source": [
        "test_df = pd.read_csv(f\"{CFG_DEB_SIMPLE.input_path}test.csv\")\n",
        "titles = pd.read_csv('../input/cpc-codes/titles.csv')\n",
        "test_df = test_df.merge(titles, left_on='context', right_on='code')\n",
        "# ====================================================\n",
        "# CPC Data\n",
        "# ====================================================\n",
        "cpc_texts = torch.load(\"../input/folds-dump-the-two-paths-fix/cpc_texts.pth\")\n",
        "test_df['context_text'] = test_df['context'].map(cpc_texts)\n",
        "test_df['text'] = test_df['anchor'] + '[SEP]' + test_df['target'] + '[SEP]'  + test_df['context_text']\n",
        "test_df['text'] = test_df['text'].apply(str.lower)\n",
        "display(test_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nD0aJh7Q9OxH"
      },
      "source": [
        "# Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2GiW-cb19OxH",
        "outputId": "90f3951c-92f7-405f-d7bb-5778b7cd99de"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-38c6ae5ff95a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenizer_deberta_v3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCFG_DEB_SIMPLE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'CFG_DEB_SIMPLE' is not defined"
          ]
        }
      ],
      "source": [
        "tokenizer_deberta_v3 = AutoTokenizer.from_pretrained(CFG_DEB_SIMPLE.model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSK5uH5t9OxH"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oqc4ycez9OxI"
      },
      "outputs": [],
      "source": [
        "class TestDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, max_input_length):\n",
        "        self.text = df['text'].values.astype(str)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_input_length = max_input_length\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        inputs = self.text[item]\n",
        "        \n",
        "        inputs = self.tokenizer(inputs,\n",
        "                    max_length=self.max_input_length,\n",
        "                    padding='max_length',\n",
        "                    truncation=True )\n",
        "        return torch.as_tensor(inputs['input_ids'], dtype=torch.long),\\\n",
        "               torch.as_tensor(inputs['token_type_ids'], dtype=torch.long),\\\n",
        "               torch.as_tensor(inputs['attention_mask'], dtype=torch.long)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CY5zujJ49OxJ"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZ8Nm2YY9OxJ"
      },
      "outputs": [],
      "source": [
        "class Custom_Bert_Simple(nn.Module):\n",
        "    def __init__(self, model_path):\n",
        "        super().__init__()\n",
        "        \n",
        "        config = AutoConfig.from_pretrained(model_path)\n",
        "        config.num_labels = 1\n",
        "        self.base = AutoModelForSequenceClassification.from_config(config=config)\n",
        "        dim = config.hidden_size\n",
        "        self.dropout = nn.Dropout(p=0)\n",
        "        self.cls = nn.Linear(dim,1)\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask, token_type_ids, labels=None):\n",
        "        base_output = self.base(input_ids=input_ids,\n",
        "                                attention_mask=attention_mask,\n",
        "                               token_type_ids=token_type_ids )\n",
        "\n",
        "        output = base_output[0]\n",
        "        if labels is None:\n",
        "            return output\n",
        "        \n",
        "        else:\n",
        "            return (nn.MSELoss()(torch.squeeze(output,1),labels), output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iDq3cid9OxJ"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBbQia7p9OxK"
      },
      "outputs": [],
      "source": [
        "def valid_fn(valid_loader, model, device):\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    labels = []\n",
        "    for step, batch in enumerate(valid_loader):\n",
        "        input_ids, token_type_ids, attention_mask = [i.to(device) for i in batch]\n",
        "        with torch.no_grad():\n",
        "            y_preds = model(input_ids, attention_mask, token_type_ids)\n",
        "        preds.append(y_preds.to('cpu').numpy())\n",
        "    predictions = np.concatenate(preds)\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGgQCFED9OxK"
      },
      "source": [
        "## deberta simple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRgeyrlH9OxK"
      },
      "outputs": [],
      "source": [
        "predictions = []\n",
        "MMscaler = MinMaxScaler()\n",
        "te_dataset = TestDataset(test_df, tokenizer_deberta_v3, CFG_DEB_SIMPLE.max_input_length)\n",
        "te_dataloader = DataLoader(te_dataset,\n",
        "                              batch_size=CFG_DEB_SIMPLE.batch_size * 2,\n",
        "                              shuffle=False,\n",
        "                              num_workers=CFG_DEB_SIMPLE.num_workers, pin_memory=True, drop_last=False)\n",
        "for fold in tqdm(range(CFG_DEB_SIMPLE.num_fold)):\n",
        "    \n",
        "    model = Custom_Bert_Simple(CFG_DEB_SIMPLE.model_path)\n",
        "    model.load_state_dict(torch.load('../input/us-patent-deberta-simple/microsoft_deberta-v3-large_best{}.pth'.format(fold))['model'])\n",
        "    model.to('cuda')\n",
        "    \n",
        "    outputs = valid_fn(te_dataloader, model, 'cuda')\n",
        "    prediction = outputs.reshape(-1)\n",
        "    predictions.append(MMscaler.fit_transform(prediction.reshape(-1,1)).reshape(-1))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHghdESC9OxL"
      },
      "outputs": [],
      "source": [
        "len(predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KJmiw6-9OxL"
      },
      "source": [
        "## post process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rGNAKdT9OxL"
      },
      "outputs": [],
      "source": [
        "predictions = np.mean(predictions, axis=0)\n",
        "predictions = np.where(predictions<=0, 0, predictions)\n",
        "predictions = np.where(predictions>=1, 1, predictions)\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'score': predictions,\n",
        "})\n",
        "\n",
        "submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7CDHrMh9OxL"
      },
      "outputs": [],
      "source": [
        "submission.to_csv('submission.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G02yCjL39OxL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}